---
title: "Pub Quiz: Summing Two Random Variables"
date: "2024-01-13"
categories: [probability, pub quiz]
description: "My company's holiday pub quiz almost had a question about summing two random variables."
reading-time: true

reference-location: document
citation-location: document
bibliography: references.bib
citations-hover: true
---

## # Pub Quiz

Last week, my company held a pub quiz.  This was no ordinary pub quiz, it was designed in a way for teams to learn about other teams.  One person from each team submitted four questions about their team.  We ended up wtih about 60 questions from all across the company.  And when I say "all" I mean _all_.  We had questions about Data Science, Commercial, Operations, Engineering, Product, Marketing, Leadership, Human Resources, you name it. As someone who is fairly familiar with all aspects of our products and engineering teams (but by no means an expert in all these areas) by having been here over four years and written my share of documentation, I came into the pub quiz _with confidence_.  Much of that confidence due to expecting to not need to know British pop culture back through the 70s as is standard in an actual pub quiz.  

That confidence was quickly smashed with questions like:

- _What was the 2023 Coca Cola Christmas commercial slogan?_
- _What is the collective age of the Customer Support team?_
- _What month was repo XXX created?_

The Data Science round was the trickiest of them all, in no small part because reading the question took up almost all of the response time!  After the quiz, my teammate who wrote the Data Science questions shared one that didn't quite make the cut.  

I share the question with the reader here, with only some minor rewording.  My answer follows.

\

## # Question

### ## The preamble
You fit the following univariate regression model using Ordinary Least Squares (OLS)

::: {.column-margin}
In the original question, the OLS abbreviation was given without the unabbreviated form.  Not sure it would have made the question any easier.
:::

$$
y = \alpha + \beta x + \epsilon
$$

Where the residual, $\epsilon$, is Normally distributed with mean 0 and standard deviation 1, that is: 

$$
\epsilon \sim {N}(0, 1)
$$

From OLS, you determine: 

- $\alpha=3$
- $\beta=2$

---

The next month, your colleague reruns the experiement and collects the same size dataset.  They forgot to check the callibration of the machine used to collect the data and as a result the dataset now has a measurement error, $u$.  That is,

$$
\displaylines{
    \begin{align}
    y^* &\equiv y + u \\ 
    y^* &= \alpha^* + \beta^*x + \epsilon^*
    \end{align}
}
$$

The measurement error has mean 2 and standard deviation 2.  
$$
u \sim N(2,2)
$$

The residuals in the new sample dataset are also normally distributed.  
$$
\epsilon^* \sim {N}(\mu^*, \sigma^*)
$$
\

### ## And finally the question
What values does your colleague find when running a regression with OLS? (Try solving with a pen and paper):

- $\alpha^* = \text{ ??}$
- $\beta^* = \text{ ??}$
- $u^* = \text{ ??}$
- $\sigma^* = \text{ ??}$
\

## # Analytical solution

There's a few things to immediately note: 

1. The _hell_ this is a pub quiz question!  
2. We assume $y^*$, $\epsilon$, $u$, and $\epsilon^*$ are independent random variables.  If they weren't, this would be a wee bit trickier (we would need to have information about the joint distributions, i.e. covariances).
3. We recognize that the new residuals are going to include the previous residuals as well as the new measurement error, $\epsilon^* = \epsilon + u$.
4. Whether it was a typo or meant to be tricky, the question states the standard deviation rather than the variance for the Normal distribution.  Typically, the notation is $N(\mu, \sigma^2)$.  Rewriting into the standard notation:

::: {.column-margin}
I've highly probably in all likelihood had the same question on a Probability exam during my Statistics postgrad.
:::

$$
\displaylines{
    \begin{alignat*}{2}
    \epsilon &\sim N(0, 1) && \rightarrow N(0, 1) \\
    u &\sim N(2, 2) && \rightarrow N(2, 4) \\
    \epsilon^* &\sim N(\mu^*, \sigma^{*}) && \rightarrow N(\mu^*, \sigma^{*2})
    \end{alignat*}
}
$$
\

The problem boils down to realizing that we have a summation of two independent Normally distributed random variables, $y$ and $u$.  How do independent Normally distributed random variables sum?  If you don't remember, don't worry, neither did I.  After some revision we know that [@ross2010]:

$$
\displaylines{
    \begin{align}
    \text{E}[X + Y]   &= \text{E}[X] + \text{E}[Y] \\
    \text{Var}[X + Y] &= \text{Var}[X] + \text{Var}[Y] + 2\text{Cov}[X,Y]
    \end{align}
}
$$

The assumption that the random variables are independent means the covariance is zero, $2\text{Cov}[X,Y] = 0$.  We can simply add the means and variances [@ross2010, pp. 256-257] giving:

$$
\displaylines{
    \begin{alignat*}{2}
    y^* &= y &&+ u \\
        &= \alpha + \beta x &&+ \epsilon + u \\
        &= \alpha + \beta x &&+ \epsilon^* \\
        &= \alpha + \beta x &&+ \Big( N(\mu_{\epsilon}, \sigma_{\epsilon}^2) + N(\mu_u, \sigma_u^2) \Big) \\
        &= \alpha + \beta x &&+ \Big( N(\mu_{\epsilon} + \mu_u, \sigma_{\epsilon}^2 + \sigma_u^2) \Big) \\
        &= \alpha + \beta x &&+ N(0 + 2, 1 + 4) \\
        &= \alpha + \beta x &&+ N(2, 5) \\
    \end{alignat*}
}
$$

where,

:::: {.columns}
::: {.column width="20%"}
<!-- empty column to create gap -->
:::
::: {.column width="30%"}
$$
\displaylines{
    \begin{alignat*}{2}
    \mu_{\epsilon^*} &= \mu_{\epsilon} &&+ \mu_u \\
        &= 0 &&+ 2 \\
        &= 2
    \end{alignat*}
}
$$
:::
::: {.column width="30%"}
$$
\displaylines{
    \begin{alignat*}{2}
    \sigma_{\epsilon^*}^2 &= \sigma_{\epsilon}^2 &&+ \sigma_u^2 \\
        &= 1 &&+ 4 \\
        &= 5
    \end{alignat*}
}
$$
:::
::: {.column width="20%"}
<!-- empty column to create gap -->
:::
::::

Plugging in the values for $\alpha$ and $\beta$, we find the following solution:
$$
y^* = 3 + 2x + N(2, 5)
$$

- $\alpha^* = 3$
- $\beta^* = 2$
- $u^* = 2$
- $\sigma^* = \sqrt{5}$
\

::: {.column-margin}
Remember, we were asked for $\sigma^*$ not $\sigma^{*2}$.
:::

We can arguably simplify this a bit further by noting that the bias, $\alpha$, and the mean of the residuals, $\mu_{\epsilon^*}$, are both constants that shift the intercept and can be grouped.  Subtracting the mean of the error from the bias...  

$$
\displaylines{
    \begin{alignat*}{3}
    y^* &= \alpha &&+ \beta x &&&+ N(2, 5) \\
        &= 3      &&+ 2x      &&&+ N(2, 5) \\
        &= (3-2)  &&+ 2x      &&&+ N(0, 5) \\
        &= 1      &&+ 2x      &&&+ N(0,5)
    \end{alignat*}
}
$$

And rewritting using the standard deviation rather than the variance (like in the original question) we arrive at:

$$
y = 1 + 2x + N(0,\sqrt{5})
$$

- $\alpha^* = 1$
- $\beta^* = 2$
- $u^* = 2$
- $\sigma^* = \sqrt{5}$
\

## # Quantative solution

## # In the end, it didn't even matter

Thankfully, this question didn't make it into our company pub quiz.  Even if it had, I think everyone (sans the author) would have had to ultimately guess the answer.  We only had 30 seconds per question.  I didn't even finish reading the problem statement let alone begin tackling it in that time!

In the end, whether this question would have been included or not, wouldn't have changed the outcome.  The quiz was neck and neck between 3 teams for most of the game.  My team bouncing between $\text{1}^{st}$ and $\text{3}^{rd}$ place.  That is until the final round of questions from the Leadership team, which were highly specific to a certain someone.   

::: {.column-margin}
If we have another pub quiz, I'll make sure to sling in some equally maladjusted questions.  But I'll post the answers beforehand here.  
\
Watch this space.
:::

Good thing I had the CEO on my team ðŸ¥‡
